{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Load Data\n",
    "作業に必要なライブラリをインポートして、 以下のデータを読み込みます。\n",
    "\n",
    "* stock_price : 株価情報\n",
    "* stock_list : 銘柄情報\n",
    "* stock_fin : 財務諸表\n",
    "* stock_labels : 目的変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.debian.org/debian-security stretch/updates InRelease [53.0 kB]\n",
      "Ign:2 http://deb.debian.org/debian stretch InRelease                      \n",
      "Get:3 http://deb.debian.org/debian stretch-updates InRelease [93.6 kB]\n",
      "Hit:4 http://deb.debian.org/debian stretch Release          \n",
      "Get:5 http://security.debian.org/debian-security stretch/updates/main amd64 Packages [660 kB]\n",
      "Fetched 807 kB in 0s (1360 kB/s)                           \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:6.3.0-4).\n",
      "gcc is already the newest version (4:6.3.0-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 61 not upgraded.\n",
      "Requirement already satisfied: shap==0.37.0 in /opt/conda/lib/python3.7/site-packages (0.37.0)\n",
      "Requirement already satisfied: slicer==0.0.3 in /opt/conda/lib/python3.7/site-packages (0.0.3)\n",
      "Requirement already satisfied: xgboost==1.3.0.post0 in /opt/conda/lib/python3.7/site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (4.31.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (0.24.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (1.16.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (1.2.1)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (0.43.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from shap==0.37.0) (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas->shap==0.37.0) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas->shap==0.37.0) (2018.9)\n",
      "Requirement already satisfied: llvmlite>=0.28.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba->shap==0.37.0) (0.28.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->shap==0.37.0) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# shap用にg++とgccをインストールします\n",
    "! apt-get update\n",
    "! apt-get install -y --no-install-recommends g++ gcc\n",
    "\n",
    "# 必要なライブラリをインストールします\n",
    "! pip install shap==0.37.0 slicer==0.0.3 xgboost==1.3.0.post0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from split_data import SplitData\n",
    "\n",
    "# 表示用の設定を変更します\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "# python 3.7.3であることを確認します\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット保存先ディレクトリ（\"\"の中身はご自身の環境に合わせて定義してください。）\n",
    "dataset_dir=\"/path/to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_list\n",
      "stock_price\n",
      "stock_fin\n",
      "stock_labels\n"
     ]
    }
   ],
   "source": [
    "# 読み込むファイルを定義します。\n",
    "inputs = {\n",
    "    \"stock_list\": f\"{dataset_dir}/stock_list.csv.gz\",\n",
    "    \"stock_price\": f\"{dataset_dir}/stock_price.csv.gz\",\n",
    "    \"stock_fin\": f\"{dataset_dir}/stock_fin.csv.gz\",\n",
    "    # 本チュートリアルでは使用しないため、コメントアウトしています。\n",
    "    # \"stock_fin_price\": f\"{dataset_dir}/stock_fin_price.csv.gz\",\n",
    "    \"stock_labels\": f\"{dataset_dir}/stock_labels.csv.gz\",\n",
    "}\n",
    "\n",
    "# ファイルを読み込みます\n",
    "dfs = {}\n",
    "for k, v in inputs.items():\n",
    "    print(k)\n",
    "    dfs[k] = pd.read_csv(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_FIN_DATA_COLUMNS = ['Result_FinancialStatement FiscalYear', 'Result_FinancialStatement NetSales',\n",
    "       'Result_FinancialStatement OperatingIncome', 'Result_FinancialStatement OrdinaryIncome',\n",
    "       'Result_FinancialStatement NetIncome', 'Result_FinancialStatement TotalAssets',\n",
    "       'Result_FinancialStatement NetAssets', 'Result_FinancialStatement CashFlowsFromOperatingActivities',\n",
    "       'Result_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "       'Result_FinancialStatement CashFlowsFromInvestingActivities', 'Forecast_FinancialStatement FiscalYear',\n",
    "       'Forecast_FinancialStatement NetSales', 'Forecast_FinancialStatement OperatingIncome',\n",
    "       'Forecast_FinancialStatement OrdinaryIncome', 'Forecast_FinancialStatement NetIncome',\n",
    "       'Result_Dividend FiscalYear', 'Result_Dividend QuarterlyDividendPerShare',\n",
    "       'Result_Dividend AnnualDividendPerShare', 'Forecast_Dividend FiscalYear',\n",
    "       'Forecast_Dividend QuarterlyDividendPerShare', 'Forecast_Dividend AnnualDividendPerShare',\n",
    "       'IssuedShareEquityQuote IssuedShare','Section/Products', '33 Sector(Code)', '17 Sector(Code)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_products = {\n",
    "    \"First Section (Domestic)\" : 1,\n",
    "    \"JASDAQ(Standard / Domestic)\" :2,\n",
    "    \"Second Section(Domestic)\" :3,\n",
    "    \"Mothers (Domestic)\" : 4,\n",
    "    \"JASDAQ(Growth/Domestic)\" :5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_glossary_of_financial_analysis(row):\n",
    "    operating_profit_margin = 0\n",
    "    ordinary_profit_margin = 0\n",
    "    net_profit_margin = 0\n",
    "    total_asset_turnover = 0\n",
    "    net_sales_growth_rate = 0\n",
    "    ordinary_income_growth_rate = 0\n",
    "    operationg_income_growth_rate = 0\n",
    "    total_assets_growth_rate = 0\n",
    "    net_assets_growth_rate = 0\n",
    "    eps = 0\n",
    "    bps = 0\n",
    "    roe = 0\n",
    "\n",
    "    # 売上高営業利益率 売上高営業利益率（％）＝営業利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        operating_profit_margin = \\\n",
    "            row['Result_FinancialStatement OperatingIncome'] / \\\n",
    "            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 売上高経常利益率　売上高経常利益率（％）＝経常利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        ordinary_profit_margin = \\\n",
    "            row['Result_FinancialStatement OrdinaryIncome'] / \\\n",
    "            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 売上高純履歴率　売上高純利益率（％）＝当期純利益÷売上高×100\n",
    "    if row['Result_FinancialStatement NetSales'] != 0:\n",
    "        net_profit_margin = row['Result_FinancialStatement NetIncome'] / \\\n",
    "                            row['Result_FinancialStatement NetSales'] * 100\n",
    "    # 総資本回転率 総資本回転率（％）＝売上高÷総資本（自己資本＋他人資本）×100\n",
    "    if row['Result_FinancialStatement NetAssets'] != 0:\n",
    "        total_asset_turnover = row['Result_FinancialStatement NetSales'] / \\\n",
    "                            row['Result_FinancialStatement NetAssets'] * 100\n",
    "    # 売上高増加率\n",
    "    if row['Previous_FinancialStatement NetSales'] != 0:\n",
    "        net_sales_growth_rate = \\\n",
    "            (row['Result_FinancialStatement NetSales'] -\n",
    "            row['Previous_FinancialStatement NetSales']) / \\\n",
    "            row['Previous_FinancialStatement NetSales'] * 100\n",
    "    # 経常利益増加率\n",
    "    if row['Previous_FinancialStatement OrdinaryIncome'] != 0:\n",
    "        ordinary_income_growth_rate = \\\n",
    "            (row['Result_FinancialStatement OrdinaryIncome'] -\n",
    "            row['Previous_FinancialStatement OrdinaryIncome']) / \\\n",
    "            row['Previous_FinancialStatement OrdinaryIncome'] * 100\n",
    "\n",
    "    # 営業利益増加率\n",
    "    if row['Previous_FinancialStatement OperatingIncome'] != 0:\n",
    "        operationg_income_growth_rate = \\\n",
    "            (row['Result_FinancialStatement OperatingIncome'] -\n",
    "            row['Previous_FinancialStatement OperatingIncome']) / \\\n",
    "            row['Previous_FinancialStatement OperatingIncome'] * 100\n",
    "    # 総資本増加率\n",
    "    if row['Previous_FinancialStatement TotalAssets'] != 0:\n",
    "        total_assets_growth_rate = \\\n",
    "            (row['Result_FinancialStatement TotalAssets'] -\n",
    "            row['Previous_FinancialStatement TotalAssets']) / \\\n",
    "            row['Previous_FinancialStatement TotalAssets'] * 100\n",
    "    # 純資本増加率\n",
    "    if row['Previous_FinancialStatement NetAssets'] != 0:\n",
    "        net_assets_growth_rate = \\\n",
    "            (row['Result_FinancialStatement NetAssets'] -\n",
    "            row['Previous_FinancialStatement NetAssets']) / \\\n",
    "            row['Previous_FinancialStatement NetAssets'] * 100\n",
    "    # 一株当たり当期純利益（EPS）\n",
    "    if row['IssuedShareEquityQuote IssuedShare'] != 0:\n",
    "        eps = row['Result_FinancialStatement NetIncome'] / \\\n",
    "            row['IssuedShareEquityQuote IssuedShare']\n",
    "        # BPS 一株当たり純資産（円） ＝ 純資産 ÷ 発行済株式総数\n",
    "        bps = row['Result_FinancialStatement NetAssets'] / \\\n",
    "            row['IssuedShareEquityQuote IssuedShare']\n",
    "        # ROE EPS（一株当たり利益）÷ BPS（一株当たり純資産）× 100\n",
    "        if bps > 0:\n",
    "            roe = eps / bps * 100\n",
    "    return pd.Series(\n",
    "        [operating_profit_margin, ordinary_profit_margin,\n",
    "            net_profit_margin, total_asset_turnover,\n",
    "            net_sales_growth_rate, ordinary_income_growth_rate,\n",
    "            operationg_income_growth_rate, total_assets_growth_rate,\n",
    "            net_assets_growth_rate, eps, bps, roe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_END = \"2017-12-31\"\n",
    "VAL_START = \"2018-02-01\"\n",
    "VAL_END = \"2018-12-01\"\n",
    "TEST_START = \"2019-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_predict(dfs, code):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict)  : dict of pd.DataFrame include stock_fin, stock_price\n",
    "        code (int)  : A local code for a listed company\n",
    "    Returns:\n",
    "        feature DataFrame (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    # おおまかな手順の1つ目\n",
    "    # stock_finデータを読み込み\n",
    "    stock_fin = dfs[\"stock_fin\"].copy()\n",
    "    \n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    stock_fin = pd.merge(stock_fin, stock_list, on=[\"Local Code\"] )\n",
    "\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    fin_data = stock_fin[stock_fin[\"Local Code\"] == code].copy()\n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    fin_data[\"datetime\"] = pd.to_datetime(fin_data[\"base_date\"])\n",
    "    fin_data.set_index(\"datetime\", inplace=True)\n",
    "    # fin_dataを選択\n",
    "    fin_data = fin_data[SELECT_FIN_DATA_COLUMNS]\n",
    "    fin_data = fin_data.join(fin_data[['Result_FinancialStatement NetSales', 'Result_FinancialStatement OperatingIncome', \n",
    "                                   'Result_FinancialStatement OrdinaryIncome', 'Result_FinancialStatement NetIncome', \n",
    "                                   'Result_FinancialStatement TotalAssets', 'Result_FinancialStatement NetAssets',\n",
    "                                   'Result_FinancialStatement CashFlowsFromOperatingActivities', \n",
    "                                   'Result_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "                                   'Result_FinancialStatement CashFlowsFromInvestingActivities']].rename(columns =\n",
    "                                                                                                         {'Result_FinancialStatement NetSales': 'Previous_FinancialStatement NetSales',\n",
    "                                                                                                          'Result_FinancialStatement OperatingIncome': 'Previous_FinancialStatement OperatingIncome', \n",
    "                                                                                                          'Result_FinancialStatement OrdinaryIncome': 'Previous_FinancialStatement OrdinaryIncome', \n",
    "                                                                                                          'Result_FinancialStatement NetIncome':'Previous_FinancialStatement NetIncome', \n",
    "                                                                                                          'Result_FinancialStatement TotalAssets': 'Previous_FinancialStatement TotalAssets', \n",
    "                                                                                                          'Result_FinancialStatement NetAssets':'Previous_FinancialStatement NetAssets',\n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromOperatingActivities': 'Previous_FinancialStatement CashFlowsFromOperatingActivities', \n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromFinancingActivities':'Previous_FinancialStatement CashFlowsFromFinancingActivities',\n",
    "                                                                                                          'Result_FinancialStatement CashFlowsFromInvestingActivities':'Previous_FinancialStatement CashFlowsFromInvestingActivities'}).shift(-1))\n",
    "    fin_data[['operating_profit_margin', 'ordinary_profit_margin', 'net_profit_margin', 'total_asset_turnover',\n",
    "         'net_sales_growth_rate', 'ordinary_income_growth_rate', 'operationg_income_growth_rate',\n",
    "          'total_assets_growth_rate', 'net_assets_growth_rate', 'eps', 'bps', 'roe']] = fin_data.apply(calculate_glossary_of_financial_analysis, axis=1)\n",
    "\n",
    "    # 欠損値処理\n",
    "    fin_feats = fin_data.fillna(0)\n",
    "\n",
    "    # おおまかな手順の2つ目\n",
    "    # stock_priceデータを読み込む\n",
    "    price = dfs[\"stock_price\"].copy()\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    price_data = price[price[\"Local Code\"] == code].copy()\n",
    "    # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "    price_data[\"datetime\"] = pd.to_datetime(price_data[\"EndOfDayQuote Date\"])\n",
    "    price_data.set_index(\"datetime\", inplace=True)\n",
    "    # 終値のみに絞る\n",
    "    feats = price_data[[\"EndOfDayQuote ExchangeOfficialClose\"]].copy()\n",
    "    # 終値の20営業日リターン\n",
    "    feats[\"return_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(20)\n",
    "    # 終値の40営業日リターン\n",
    "    feats[\"return_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(40)\n",
    "    # 終値の60営業日リターン\n",
    "    feats[\"return_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(60)\n",
    "    # 終値の20営業日ボラティリティ\n",
    "    feats[\"volatility_1month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(20).std()\n",
    "    )\n",
    "    # 終値の40営業日ボラティリティ\n",
    "    feats[\"volatility_2month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(40).std()\n",
    "    )\n",
    "    # 終値の60営業日ボラティリティ\n",
    "    feats[\"volatility_3month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(60).std()\n",
    "    )\n",
    "    # 終値と20営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(20).mean()\n",
    "    )\n",
    "    # 終値と40営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(40).mean()\n",
    "    )\n",
    "    # 終値と60営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(60).mean()\n",
    "    )\n",
    "    \n",
    "    # EWMA\n",
    "    ALPHA = 0.25\n",
    "    feats[\"EWMA\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"]\n",
    "\n",
    "    for t in zip(feats.index, feats.index[1:]):\n",
    "        feats.loc[t[1], \"EWMA\"] = ALPHA * feats.loc[t[1], \"EndOfDayQuote ExchangeOfficialClose\"] + (1 - ALPHA) * feats.loc[t[0], \"EWMA\"]\n",
    "    \n",
    "    # EMA 10日\n",
    "    feats[\"ema_10\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=10).mean()\n",
    "    \n",
    "    # MACD \n",
    "    # EMA12\n",
    "    feats[\"ema_12\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=12).mean()\n",
    "    # EMA 26\n",
    "    feats[\"ema_26\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].ewm(span=26).mean()\n",
    "    feats[\"macd\"] = feats[\"ema_12\"] - feats[\"ema_26\"]\n",
    "    feats[\"signal\"] = feats[\"macd\"].ewm(span=9).mean()\n",
    "    \n",
    "    # PBR 株価 ÷ BPS（1株あたり純資産）\n",
    "    feats[\"pbr\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / fin_data[\"bps\"]\n",
    "    # PER 株価 ÷ 1株当たり利益（EPS）\n",
    "    feats[\"per\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / fin_data[\"eps\"]\n",
    "\n",
    "    # おおまかな手順の3つ目\n",
    "    # 欠損値処理\n",
    "    feats = feats.fillna(0)\n",
    "    # 元データのカラムを削除\n",
    "    feats = feats.drop([\"EndOfDayQuote ExchangeOfficialClose\"], axis=1)\n",
    "\n",
    "    # 財務データの特徴量とマーケットデータの特徴量のインデックスを合わせる\n",
    "    feats = feats.loc[feats.index.isin(fin_feats.index)]\n",
    "    fin_feats = fin_feats.loc[fin_feats.index.isin(feats.index)]\n",
    "\n",
    "    # データを結合\n",
    "    feats = pd.concat([feats, fin_feats], axis=1).dropna()\n",
    "\n",
    "    # 欠損値処理を行います。\n",
    "    feats = feats.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # 市場・商品区分を数値に変換\n",
    "    feats[\"Section/Products\"] = section_products[feats[\"Section/Products\"][0]]\n",
    "    # 銘柄コードを設定\n",
    "    feats[\"code\"] = code\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(dfs, codes, feature, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "        codes  (array) : target codes\n",
    "        feature (pd.DataFrame): features\n",
    "        label (str) : label column name\n",
    "    Returns:\n",
    "        train_X (pd.DataFrame): training data\n",
    "        train_y (pd.DataFrame): label for train_X\n",
    "        val_X (pd.DataFrame): validation data\n",
    "        val_y (pd.DataFrame): label for val_X\n",
    "        test_X (pd.DataFrame): test data\n",
    "        test_y (pd.DataFrame): label for test_X\n",
    "    \"\"\"\n",
    "    # 分割データ用の変数を定義\n",
    "    trains_X, vals_X, tests_X = [], [], []\n",
    "    trains_y, vals_y, tests_y = [], [], []\n",
    "\n",
    "    # 銘柄コード毎に特徴量を作成\n",
    "    for i, code in enumerate(tqdm(codes)):\n",
    "#    for code in tqdm(codes):\n",
    "        # 特徴量取得\n",
    "        feats = feature[feature[\"code\"] == code]\n",
    "\n",
    "        # stock_labelデータを読み込み\n",
    "        stock_labels = dfs[\"stock_labels\"].copy()\n",
    "        # 特定の銘柄コードのデータに絞る\n",
    "        stock_labels = stock_labels[stock_labels[\"Local Code\"] == code]\n",
    "        # 日付列をpd.Timestamp型に変換してindexに設定\n",
    "        stock_labels[\"datetime\"] = pd.to_datetime(stock_labels[\"base_date\"])\n",
    "        stock_labels.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "        # 特定の目的変数に絞る\n",
    "        labels = stock_labels[label]\n",
    "        # nanを削除\n",
    "        labels.dropna(inplace=True)\n",
    "\n",
    "        if feats.shape[0] > 0 and labels.shape[0] > 0:\n",
    "            # 特徴量と目的変数のインデックスを合わせる\n",
    "            labels = labels.loc[labels.index.isin(feats.index)]\n",
    "            feats = feats.loc[feats.index.isin(labels.index)]\n",
    "            labels.index = feats.index\n",
    "\n",
    "            # データを分割（ホールドアウト法）\n",
    "            _train_X = feats[: TRAIN_END].copy()\n",
    "            _val_X = feats[VAL_START : VAL_END].copy()\n",
    "            _test_X = feats[TEST_START :].copy()\n",
    "\n",
    "            _train_y = labels[: TRAIN_END].copy()\n",
    "            _val_y = labels[VAL_START : VAL_END].copy()\n",
    "            _test_y = labels[TEST_START :].copy()\n",
    "\n",
    "             # データを配列に格納 (後ほど結合するため)\n",
    "            trains_X.append(_train_X)\n",
    "            vals_X.append(_val_X)\n",
    "            tests_X.append(_test_X)\n",
    "\n",
    "            trains_y.append(_train_y)\n",
    "            vals_y.append(_val_y)\n",
    "            tests_y.append(_test_y)\n",
    "\n",
    "        if i == 0:\n",
    "            # 初回はデータをnumpy配列に変換する\n",
    "            train_X = SplitData(_train_X)\n",
    "            val_X = SplitData(_val_X)\n",
    "            test_X = SplitData(_test_X)\n",
    "            train_y = SplitData(_train_y)\n",
    "            val_y = SplitData(_val_y)\n",
    "            test_y = SplitData(_test_y)\n",
    "        else:\n",
    "            train_X.add_data(_train_X)\n",
    "            val_X.add_data(_val_X)\n",
    "            test_X.add_data(_test_X)\n",
    "            train_y.add_data(_train_y)\n",
    "            val_y.add_data(_val_y)\n",
    "            test_y.add_data(_test_y)\n",
    "            \n",
    "    return train_X.get_data(), train_y.get_data(), val_X.get_data(), val_y.get_data(), test_X.get_data(), test_y.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(dfs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "    Returns:\n",
    "        array: list of stock codes\n",
    "    \"\"\"\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    # 予測対象の銘柄コードを取得\n",
    "    codes = stock_list[stock_list[\"prediction_target\"] == True][\n",
    "        \"Local Code\"\n",
    "    ].values\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model\")\n",
    "\n",
    "with open(os.path.join(model_path, \"feature.pkl\"), \"rb\") as f:\n",
    "    feature = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象の目的変数を定義\n",
    "labels = {\n",
    "    \"label_high_5\",\n",
    "    \"label_high_10\",\n",
    "    \"label_high_20\",\n",
    "    \"label_low_5\",\n",
    "    \"label_low_10\",\n",
    "    \"label_low_20\",\n",
    "}\n",
    "# 目的変数毎にデータを保存するための変数\n",
    "train_X, val_X, test_X = {}, {}, {}\n",
    "train_y, val_y, test_y = {}, {}, {}\n",
    "\n",
    "# 予測対象銘柄を取得\n",
    "codes = get_codes(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0553ae2b401c43b0a5d58c78455afb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900a9433cc2d4cca9009e08e294f76cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a02ef5ac444f91a5c4ce4710bf9d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf0aa9d99ac4eb0b26037e96a9a1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efffce9ec46e409097e774396a4b766a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393afec091d94f3c8377572acd5b9198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcddc6445977428091db1da563364e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 目的変数毎に処理\n",
    "for label in tqdm(labels):\n",
    "    # 特徴量と目的変数を取得\n",
    "    _train_X, _train_y, _val_X, _val_y, _test_X, _test_y = get_features_and_label(dfs, codes, feature, label)\n",
    "    # 目的変数をキーとして値を保存\n",
    "    train_X[label] = _train_X\n",
    "    val_X[label] = _val_X\n",
    "    test_X[label] = _test_X\n",
    "    train_y[label] = _train_y\n",
    "    val_y[label] = _val_y\n",
    "    test_y[label] = _test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3523, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['label_high_20'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/class/np_test_X/\")\n",
    "# tag::save_model[]\n",
    "# モデル保存先ディレクトリを作成\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "for label in labels:\n",
    "    with open(os.path.join(model_path, f\"np_test_X_{label}.pkl\"), \"wb\") as f:\n",
    "        # モデルをpickle形式で保存\n",
    "        pickle.dump(test_X[label], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象銘柄コードを定義\n",
    "codes = [9984]\n",
    "# 対象の目的変数を定義\n",
    "label = \"label_high_20\"\n",
    "# 特徴量を取得\n",
    "feat = get_features_for_predict(dfs, codes[0])\n",
    "# 特徴量と目的変数を入力し、分割データを取得\n",
    "ret = get_features_and_label(dfs, codes, feat, label)\n",
    "for v in ret:\n",
    "    print(v.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(dfs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "    Returns:\n",
    "        array: list of stock codes\n",
    "    \"\"\"\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    # 予測対象の銘柄コードを取得\n",
    "    codes = stock_list[stock_list[\"prediction_target\"] == True][\n",
    "        \"Local Code\"\n",
    "    ].values\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 対象の目的変数を定義\n",
    "labels = {\n",
    "    \"label_high_5\",\n",
    "    \"label_high_10\",\n",
    "    \"label_high_20\",\n",
    "    \"label_low_5\",\n",
    "    \"label_low_10\",\n",
    "    \"label_low_20\",\n",
    "}\n",
    "# 目的変数毎にデータを保存するための変数\n",
    "train_X, val_X, test_X = {}, {}, {}\n",
    "train_y, val_y, test_y = {}, {}, {}\n",
    "\n",
    "# 予測対象銘柄を取得\n",
    "codes = get_codes(dfs)\n",
    "\n",
    "# 特徴量を作成\n",
    "buff = []\n",
    "for code in tqdm(codes):\n",
    "    feat = get_features_for_predict(dfs, code)\n",
    "    buff.append(feat)\n",
    "feature = pd.concat(buff)\n",
    "\n",
    "# 目的変数毎に処理\n",
    "for label in tqdm(labels):\n",
    "    # 特徴量と目的変数を取得\n",
    "    _train_X, _train_y, _val_X, _val_y, _test_X, _test_y = get_features_and_label(dfs, codes, feature, label)\n",
    "    # 目的変数をキーとして値を保存\n",
    "    train_X[label] = _train_X\n",
    "    val_X[label] = _val_X\n",
    "    test_X[label] = _test_X\n",
    "    train_y[label] = _train_y\n",
    "    val_y[label] = _val_y\n",
    "    test_y[label] = _test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X['label_low_10'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y['label_low_10'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model/proceed_datas/np_val_y\")\n",
    "# tag::save_model[]\n",
    "# モデル保存先ディレクトリを作成\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "for label in labels:\n",
    "    with open(os.path.join(model_path, f\"np_val_y_{label}.pkl\"), \"wb\") as f:\n",
    "        # モデルをpickle形式で保存\n",
    "        pickle.dump(val_y[label], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model\")\n",
    "# tag::save_model[]\n",
    "# モデル保存先ディレクトリを作成\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "with open(os.path.join(model_path, \"np_val_y\"), \"wb\") as f:\n",
    "    # モデルをpickle形式で保存\n",
    "    pickle.dump(val_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model\")\n",
    "\n",
    "with open(os.path.join(model_path, \"test_X\"), \"rb\") as f:\n",
    "    test_X = pickle.load(f)\n",
    "with open(os.path.join(model_path, \"test_y\"), \"rb\") as f:\n",
    "    test_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"train_X\"), \"rb\") as f:\n",
    "    train_X = pickle.load(f)\n",
    "with open(os.path.join(model_path, \"train_y\"), \"rb\") as f:\n",
    "    train_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"val_X\"), \"rb\") as f:\n",
    "    val_X = pickle.load(f)\n",
    "with open(os.path.join(model_path, \"val_y\"), \"rb\") as f:\n",
    "    val_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を指定\n",
    "label = \"label_high_20\"\n",
    "\n",
    "# 学習用データセット定義\n",
    "# ファンダメンタル情報\n",
    "#fundamental_cols = dfs[\"stock_fin\"].select_dtypes(\"float64\").columns\n",
    "fundamental_cols = pd.Index(SELECT_FIN_DATA_COLUMNS)\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Result_Dividend DividendPayableDate\"]\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Local Code\"]\n",
    "# 価格変化率\n",
    "returns_cols = [x for x in train_X[label].columns if \"return\" in x]\n",
    "# テクニカル\n",
    "technical_cols = [x for x in train_X[label].columns if (x not in fundamental_cols) and (x != \"code\")]\n",
    "\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "# 学習用データセットを指定\n",
    "col = \"fundamental+technical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''reg_cv = GridSearchCV(xgb_model, {\n",
    "    \"eta\": [0.1], \n",
    "    \"gamma\": [0.1,0.2,0.3,0.4,0.5],\n",
    "    \"n_estimators\": [50, 100, 200], \n",
    "    \"max_depth\": [5, 7, 9,10,20,30],\n",
    "    \"subsample\":[0.6,0.8,1],\n",
    "    \"colsample_bytree\": [0.5,0.7,0.9],\n",
    "}, verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'colsample_bytree': 0.5, 'eta': 0.1, 'gamma': 0.5, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1}\n",
    "0.07780464612358796\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# モデル定義\n",
    "model = XGBRegressor()\n",
    "\n",
    "# ハイパーパラメータ探索\n",
    "reg_cv = GridSearchCV(model, {\n",
    "    \"eta\": [0.1], \n",
    "    \"gamma\": [0.4, 0.5],\n",
    "    \"max_depth\": [5],\n",
    "    \"n_estimators\": [50], \n",
    "    \"subsample\":[1],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}, verbose=1)\n",
    "\n",
    "# 訓練実施\n",
    "reg_cv.fit(train_X[label][columns[col]].values, train_y[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を表示\n",
    "print(reg_cv.best_params_)\n",
    "print(reg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = reg_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を指定\n",
    "label = \"label_high_20\"\n",
    "\n",
    "# 学習用データセット定義\n",
    "# ファンダメンタル情報\n",
    "#fundamental_cols = dfs[\"stock_fin\"].select_dtypes(\"float64\").columns\n",
    "fundamental_cols = pd.Index(SELECT_FIN_DATA_COLUMNS)\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Result_Dividend DividendPayableDate\"]\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Local Code\"]\n",
    "# 価格変化率\n",
    "returns_cols = [x for x in train_X[label].columns if \"return\" in x]\n",
    "# テクニカル\n",
    "technical_cols = [x for x in train_X[label].columns if (x not in fundamental_cols) and (x != \"code\")]\n",
    "\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "# 学習用データセットを指定\n",
    "col = \"fundamental+technical\"\n",
    "\n",
    "# 学習\n",
    "#pred_model = models[model](reg_cv.best_estimator_, random_state=0)\n",
    "best_model.fit(train_X[label][columns[col]].values, train_y[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X[label][columns[col]].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[label][columns[col]].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[label][columns[col]].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[label].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[label].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[label].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "result = {}\n",
    "result[label] = pd.DataFrame(\n",
    "    best_model.predict(val_X[label][columns[col]]), columns=[\"predict\"]\n",
    ")\n",
    "\n",
    "# 予測結果に日付と銘柄コードを追加\n",
    "result[label][\"datetime\"] = val_X[label][columns[col]].index\n",
    "result[label][\"code\"] = val_X[label][\"code\"].values\n",
    "\n",
    "# 予測の符号を取得\n",
    "result[label][\"predict_dir\"] = np.sign(result[label][\"predict\"])\n",
    "\n",
    "# 実際の値を追加\n",
    "result[label][\"actual\"] = val_y[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.fit(train_X[label][columns[col]].values, train_y[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"../model\")\n",
    "# tag::save_model[]\n",
    "# モデル保存先ディレクトリを作成\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "with open(os.path.join(model_path, f\"my_model_{label}.pkl\"), \"wb\") as f:\n",
    "    # モデルをpickle形式で保存\n",
    "    pickle.dump(pred_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=result[label], x=\"predict\", y=\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルを指定\n",
    "rf = pred_model\n",
    "\n",
    "# 重要度順を取得\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.barh(fundamental_cols[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義します\n",
    "sample_model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(train_X[\"label_high_20\"], label=train_y[\"label_high_20\"]), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model=sample_model, feature_perturbation='tree_path_dependent', model_output='margin')\n",
    "# SHAP値\n",
    "shap_values = explainer.shap_values(X=train_X[\"label_high_20\"])\n",
    "# プロット\n",
    "shap.summary_plot(shap_values, train_X[\"label_high_20\"], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, train_X[\"label_high_20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モデルを定義\n",
    "models = {\n",
    "    \"rf\": RandomForestRegressor,\n",
    "    \"extraTree\": ExtraTreesRegressor,\n",
    "    \"gbr\": GradientBoostingRegressor,\n",
    "}\n",
    "\n",
    "# 学習用データセット定義\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "\n",
    "# 結果保存用\n",
    "all_results = dict()\n",
    "# モデル毎に処理\n",
    "for model in tqdm(models.keys()):\n",
    "    all_results[model] = dict()\n",
    "    # データセット毎に処理\n",
    "    for col in columns.keys():\n",
    "        result = dict()\n",
    "        # 目的変数毎に処理\n",
    "        for label in tqdm(labels):\n",
    "            if len(test_X[label][columns[col]]) > 0:\n",
    "                # モデル取得\n",
    "                pred_model = models[model](random_state=0)\n",
    "                # 学習\n",
    "                pred_model.fit(train_X[label][columns[col]].values, train_y[label])\n",
    "                # 結果データ作成\n",
    "                result[label] = test_X[label][[\"code\"]].copy()\n",
    "                result[label][\"datetime\"] = test_X[label][columns[col]].index\n",
    "                # 予測\n",
    "                result[label][\"predict\"] = pred_model.predict(test_X[label][columns[col]])\n",
    "                result[label][\"predict_dir\"] = np.sign(result[label][\"predict\"])\n",
    "                # 実際の結果\n",
    "                result[label][\"actual\"] = test_y[label].values\n",
    "                result[label][\"actual_dir\"] = np.sign(result[label][\"actual\"])\n",
    "                result[label].dropna(inplace=True)\n",
    "\n",
    "        all_results[model][col] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in all_results.keys():\n",
    "    for col in all_results[model]:\n",
    "        tmp = pd.concat(all_results[model][col])\n",
    "        tmp[\"model\"] = model\n",
    "        tmp[\"feature\"] = col\n",
    "        results.append(tmp)\n",
    "results = pd.concat(results)\n",
    "results[\"label\"] = [x[0] for x in results.index]\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果保存用変数\n",
    "all_metrics = []\n",
    "\n",
    "# データセット毎に処理\n",
    "for feature in columns:\n",
    "    matrix = dict()\n",
    "    # モデル毎に処理\n",
    "    for model in models:\n",
    "        # 目的変数毎に処理\n",
    "        for label in labels:\n",
    "            # 処理対象データに絞り込み\n",
    "            tmp_df = results[(results[\"model\"] == model) & (results[\"label\"] == label) & (results[\"feature\"] == feature)]\n",
    "            # RMSE\n",
    "            rmse = np.sqrt(mean_squared_error(tmp_df[\"predict\"], tmp_df[\"actual\"]))\n",
    "            # 精度\n",
    "            accuracy = accuracy_score(tmp_df[\"predict_dir\"], tmp_df[\"actual_dir\"])\n",
    "            # 相関係数\n",
    "            corr = np.corrcoef(tmp_df[\"actual\"], tmp_df[\"predict\"])[0, 1]\n",
    "            # 順位相関\n",
    "            spearman_corr = spearmanr(tmp_df[\"actual\"], tmp_df[\"predict\"])[0]\n",
    "            # 結果を保存\n",
    "            matrix[label] = [rmse, accuracy, spearman_corr,corr, corr**2, feature, model, tmp_df.shape[0]]\n",
    "        res = pd.DataFrame.from_dict(matrix).T\n",
    "        res.columns = [\"RMSE\",\"accuracy\",\"spearman_corr\",\"corr\",\"R^2 score\",\"feature\", \"model\", \"# of samples\"]\n",
    "        all_metrics.append(res)\n",
    "all_metrics = pd.concat(all_metrics)\n",
    "all_metrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
